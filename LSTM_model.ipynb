{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (window.IPython && IPython.notebook.kernel) IPython.notebook.kernel.execute('jovian.utils.jupyter.get_notebook_name_saved = lambda: \"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import re\n",
    "import jovian\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import string\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from collections import Counter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This new file removes gender rows other than 'male'\n",
    "#and 'female'\n",
    "tweets = pd.read_csv(r'Desktop/tweets_gender_new.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I removed unnecessary columns and also create a new\n",
    "#column which combines the description and text\n",
    "#columns\n",
    "\n",
    "tweets.pop('ï»¿unit_id')\n",
    "tweets.pop('_golden')\n",
    "tweets.pop('_unit_state')\n",
    "tweets.pop('_trusted_judgments')\n",
    "tweets.pop('_last_judgment_at')\n",
    "tweets.pop('profile_yn')\n",
    "tweets.pop('profile_yn:confidence')\n",
    "tweets.pop('created')\n",
    "tweets.pop('fav_number')\n",
    "tweets.pop('gender_gold')\n",
    "tweets.pop('link_color')\n",
    "tweets.pop('name')\n",
    "tweets.pop('profile_yn_gold')\n",
    "tweets.pop('profileimage')\n",
    "tweets.pop('retweet_count')\n",
    "tweets.pop('sidebar_color')\n",
    "tweets.pop('tweet_coord')\n",
    "tweets.pop('tweet_count')\n",
    "tweets.pop('tweet_created')\n",
    "tweets.pop('tweet_id')\n",
    "tweets.pop('tweet_location')\n",
    "tweets.pop('user_timezone')\n",
    "\n",
    "tweets['Profile'] = tweets['description'] + ' ' + tweets['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>gender:confidence</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>Profile</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>i sing my own rhythm.</td>\n",
       "      <td>Robbie E Responds To Critics After Win Against...</td>\n",
       "      <td>i sing my own rhythm. Robbie E Responds To Cri...</td>\n",
       "      <td>[[1, 2, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>I'm the author of novels filled with family dr...</td>\n",
       "      <td>Ã¢â¬ÅIt felt like they were my friends and I...</td>\n",
       "      <td>I'm the author of novels filled with family dr...</td>\n",
       "      <td>[[12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>louis whining and squealing and all</td>\n",
       "      <td>i absolutely adore when louis starts the songs...</td>\n",
       "      <td>louis whining and squealing and all i absolute...</td>\n",
       "      <td>[[25, 33, 34, 35, 36, 37, 11, 38, 17, 39, 40, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Mobile guy.  49ers, Shazam, Google, Kleiner Pe...</td>\n",
       "      <td>Hi @JordanSpieth - Looking at the url - do you...</td>\n",
       "      <td>Mobile guy.  49ers, Shazam, Google, Kleiner Pe...</td>\n",
       "      <td>[[45, 12, 1, 14, 46, 47, 11, 48, 14, 49, 50, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...</td>\n",
       "      <td>Watching Neighbours on Sky+ catching up with t...</td>\n",
       "      <td>Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...</td>\n",
       "      <td>[[63, 64, 58, 65, 12, 66, 67, 29, 11, 1, 14, 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  gender:confidence  \\\n",
       "0       1             1.0000   \n",
       "1       1             1.0000   \n",
       "2       1             0.6625   \n",
       "3       1             1.0000   \n",
       "4       0             1.0000   \n",
       "\n",
       "                                         description  \\\n",
       "0                              i sing my own rhythm.   \n",
       "1  I'm the author of novels filled with family dr...   \n",
       "2                louis whining and squealing and all   \n",
       "3  Mobile guy.  49ers, Shazam, Google, Kleiner Pe...   \n",
       "4  Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Robbie E Responds To Critics After Win Against...   \n",
       "1  Ã¢â¬ÅIt felt like they were my friends and I...   \n",
       "2  i absolutely adore when louis starts the songs...   \n",
       "3  Hi @JordanSpieth - Looking at the url - do you...   \n",
       "4  Watching Neighbours on Sky+ catching up with t...   \n",
       "\n",
       "                                             Profile  \\\n",
       "0  i sing my own rhythm. Robbie E Responds To Cri...   \n",
       "1  I'm the author of novels filled with family dr...   \n",
       "2  louis whining and squealing and all i absolute...   \n",
       "3  Mobile guy.  49ers, Shazam, Google, Kleiner Pe...   \n",
       "4  Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...   \n",
       "\n",
       "                                             encoded  \n",
       "0  [[1, 2, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1,...  \n",
       "1  [[12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, ...  \n",
       "2  [[25, 33, 34, 35, 36, 37, 11, 38, 17, 39, 40, ...  \n",
       "3  [[45, 12, 1, 14, 46, 47, 11, 48, 14, 49, 50, 5...  \n",
       "4  [[63, 64, 58, 65, 12, 66, 67, 29, 11, 1, 14, 6...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I use 1 and -1 to represent the two genders\n",
    "tweets['gender'] = tweets['gender'].replace(['male'], 1)\n",
    "tweets['gender'] = tweets['gender'].replace(['female'], 0)\n",
    "\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#tokenizing function\n",
    "def tokenize (text):\n",
    "    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n",
    "    nopunct = regex.sub(\" \", text.lower())\n",
    "    return [token.text for token in nlp.tokenizer(nopunct)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count number of occurences of each word\n",
    "#for some reason, I wasn't able to do this on the \n",
    "#'Profile' column\n",
    "counts = Counter()\n",
    "for index, row in tweets.iterrows():\n",
    "    counts.update(tokenize(row['text']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete words that occur rarely, or in other words\n",
    "#less than 2 times\n",
    "for word in list(counts):\n",
    "    if counts[word] < 2:\n",
    "        del counts[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we create a vocabulary from the text\n",
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "words = [\"\", \"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode each text as tensors/vectors\n",
    "def encode_sentence(text, vocab2index, N=70):\n",
    "    tokenized = tokenize(text)\n",
    "    encoded = np.zeros(N, dtype=int)\n",
    "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized])\n",
    "    length = min(N, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "    return encoded, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>gender:confidence</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>Profile</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>i sing my own rhythm.</td>\n",
       "      <td>Robbie E Responds To Critics After Win Against...</td>\n",
       "      <td>i sing my own rhythm. Robbie E Responds To Cri...</td>\n",
       "      <td>[[1, 2, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>I'm the author of novels filled with family dr...</td>\n",
       "      <td>Ã¢â¬ÅIt felt like they were my friends and I...</td>\n",
       "      <td>I'm the author of novels filled with family dr...</td>\n",
       "      <td>[[12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>louis whining and squealing and all</td>\n",
       "      <td>i absolutely adore when louis starts the songs...</td>\n",
       "      <td>louis whining and squealing and all i absolute...</td>\n",
       "      <td>[[25, 33, 34, 35, 36, 37, 11, 38, 17, 39, 40, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Mobile guy.  49ers, Shazam, Google, Kleiner Pe...</td>\n",
       "      <td>Hi @JordanSpieth - Looking at the url - do you...</td>\n",
       "      <td>Mobile guy.  49ers, Shazam, Google, Kleiner Pe...</td>\n",
       "      <td>[[45, 12, 1, 14, 46, 47, 11, 48, 14, 49, 50, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...</td>\n",
       "      <td>Watching Neighbours on Sky+ catching up with t...</td>\n",
       "      <td>Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...</td>\n",
       "      <td>[[63, 64, 58, 65, 12, 66, 67, 29, 11, 1, 14, 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  gender:confidence  \\\n",
       "0       1             1.0000   \n",
       "1       1             1.0000   \n",
       "2       1             0.6625   \n",
       "3       1             1.0000   \n",
       "4       0             1.0000   \n",
       "\n",
       "                                         description  \\\n",
       "0                              i sing my own rhythm.   \n",
       "1  I'm the author of novels filled with family dr...   \n",
       "2                louis whining and squealing and all   \n",
       "3  Mobile guy.  49ers, Shazam, Google, Kleiner Pe...   \n",
       "4  Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Robbie E Responds To Critics After Win Against...   \n",
       "1  Ã¢â¬ÅIt felt like they were my friends and I...   \n",
       "2  i absolutely adore when louis starts the songs...   \n",
       "3  Hi @JordanSpieth - Looking at the url - do you...   \n",
       "4  Watching Neighbours on Sky+ catching up with t...   \n",
       "\n",
       "                                             Profile  \\\n",
       "0  i sing my own rhythm. Robbie E Responds To Cri...   \n",
       "1  I'm the author of novels filled with family dr...   \n",
       "2  louis whining and squealing and all i absolute...   \n",
       "3  Mobile guy.  49ers, Shazam, Google, Kleiner Pe...   \n",
       "4  Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...   \n",
       "\n",
       "                                             encoded  \n",
       "0  [[1, 2, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1,...  \n",
       "1  [[12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, ...  \n",
       "2  [[25, 33, 34, 35, 36, 37, 11, 38, 17, 39, 40, ...  \n",
       "3  [[45, 12, 1, 14, 46, 47, 11, 48, 14, 49, 50, 5...  \n",
       "4  [[63, 64, 58, 65, 12, 66, 67, 29, 11, 1, 14, 6...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['encoded'] = tweets['text'].apply(lambda x: np.array(encode_sentence(x, vocab2index)))\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the label and input data\n",
    "X = list(tweets['encoded'])\n",
    "y = list(tweets['gender'])\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataset class\n",
    "class ProfileDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.X[idx][0].astype(np.int32)), self.y[idx], self.X[idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ProfileDataset(X_train, y_train)\n",
    "valid_ds = ProfileDataset(X_valid, y_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs=10, lr=0.001):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, y, l in train_dl:\n",
    "            x = x.long()\n",
    "            y = y.long()\n",
    "            y_pred = model(x, l)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss, val_acc, val_rmse = validation_metrics(model, val_dl)\n",
    "        if i % 5 == 1:\n",
    "            print(\"train loss %.3f, val loss %.3f, val accuracy %.3f, and val rmse %.3f\" % (sum_loss/total, val_loss, val_acc, val_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_metrics (model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    sum_rmse = 0.0\n",
    "    for x, y, l in valid_dl:\n",
    "        x = x.long()\n",
    "        y = y.long()\n",
    "        y_hat = model(x, l)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = torch.max(y_hat, 1)[1]\n",
    "        correct += (pred == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "        sum_rmse += np.sqrt(mean_squared_error(pred, y.unsqueeze(-1)))*y.shape[0]\n",
    "    return sum_loss/total, correct/total, sum_rmse/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "vocab_size = len(words)\n",
    "train_dl = DataLoader(train_ds, batch_size = batch_size, shuffle = True)\n",
    "val_dl = DataLoader(valid_ds, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this model is based on the glove word embedding space\n",
    "#download the necessary files from https://jovian.ai/outlink?url=https%3A%2F%2Fnlp.stanford.edu%2Fprojects%2Fglove%2F\n",
    "\n",
    "def load_glove_vectors(glove_file=r\"Downloads/glove/glove.twitter.27B.100d.txt\"):\n",
    "    \"\"\"Load the glove word vectors\"\"\"\n",
    "    word_vectors = {}\n",
    "    with open(glove_file) as f:\n",
    "        for line in f:\n",
    "            split = line.split()\n",
    "            word_vectors[split[0]] = np.array([float(x) for x in split[1:]])\n",
    "    return word_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb_matrix(pretrained, word_counts, emb_size = 100):\n",
    "    \"\"\" Creates embedding matrix from word vectors\"\"\"\n",
    "    vocab_size = len(word_counts) + 2\n",
    "    vocab_to_idx = {}\n",
    "    vocab = [\"\", \"UNK\"]\n",
    "    W = np.zeros((vocab_size, emb_size), dtype=\"float32\")\n",
    "    W[0] = np.zeros(emb_size, dtype='float32') # adding a vector for padding\n",
    "    W[1] = np.random.uniform(-0.25, 0.25, emb_size) # adding a vector for unknown words \n",
    "    vocab_to_idx[\"UNK\"] = 1\n",
    "    i = 2\n",
    "    for word in word_counts:\n",
    "        if word in word_vecs:\n",
    "            W[i] = word_vecs[word]\n",
    "        else:\n",
    "            W[i] = np.random.uniform(-0.25,0.25, emb_size)\n",
    "        vocab_to_idx[word] = i\n",
    "        vocab.append(word)\n",
    "        i += 1   \n",
    "    return W, np.array(vocab), vocab_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs = load_glove_vectors()\n",
    "pretrained_weights, vocab, vocab2index = get_emb_matrix(word_vecs, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_glove_vecs(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, glove_weights) :\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.embeddings.weight.data.copy_(torch.from_numpy(glove_weights))\n",
    "        self.embeddings.weight.requires_grad = False ## freeze embeddings\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 5)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x, l):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        lstm_out, (ht, ct) = self.lstm(x)\n",
    "        return self.linear(ht[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_glove_vecs(vocab_size, 100, 100, pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.213, val loss 1.054, val accuracy 0.508, and val rmse 0.702\n",
      "train loss 2.521, val loss 3.895, val accuracy 0.406, and val rmse 0.949\n",
      "train loss 0.872, val loss 0.902, val accuracy 0.508, and val rmse 0.702\n",
      "train loss 1.557, val loss 0.774, val accuracy 0.508, and val rmse 0.702\n",
      "train loss 0.765, val loss 0.735, val accuracy 0.499, and val rmse 0.708\n",
      "train loss 0.709, val loss 0.701, val accuracy 0.482, and val rmse 0.720\n"
     ]
    }
   ],
   "source": [
    "train_model(model, epochs=30, lr=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.702, val loss 0.702, val accuracy 0.489, and val rmse 0.715\n",
      "train loss 0.695, val loss 0.697, val accuracy 0.507, and val rmse 0.702\n",
      "train loss 0.696, val loss 0.703, val accuracy 0.511, and val rmse 0.699\n",
      "train loss 0.696, val loss 0.696, val accuracy 0.500, and val rmse 0.707\n",
      "train loss 0.694, val loss 0.693, val accuracy 0.520, and val rmse 0.693\n",
      "train loss 0.695, val loss 0.695, val accuracy 0.503, and val rmse 0.705\n"
     ]
    }
   ],
   "source": [
    "train_model(model, epochs=30, lr=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bit0d27d92a4f354eaeaea1089cf2aa40bd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
